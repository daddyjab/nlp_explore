{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow: Word Embeddings\n",
    "* Reference: https://www.tensorflow.org/text/guide/word_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, os, re, shutil\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the IMDB Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "84131840/84125825 [==============================] - 8s 0us/step\n",
      "84140032/84125825 [==============================] - 8s 0us/step\n"
     ]
    }
   ],
   "source": [
    "IMDB_MOVIE_REVIEW_DATA_URL = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "dataset = tf.keras.utils.get_file(\n",
    "    \"aclImdb_v1.tar.gz\", IMDB_MOVIE_REVIEW_DATA_URL,\n",
    "    untar=True, cache_dir='.', cache_subdir='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join( os.path.dirname(dataset), 'aclImdb' )\n",
    "# os.listdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "# os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_dir = os.path.join(train_dir, 'unsup')\n",
    "shutil.rmtree(remove_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "seed = 123\n",
    "train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    'aclImdb/train', batch_size=batch_size, validation_split=0.2,\n",
    "    subset='training', seed=seed)\n",
    "val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    'aclImdb/train', batch_size=batch_size, validation_split=0.2,\n",
    "    subset='validation', seed=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for text_batch, label_batch in train_ds.take(1):\n",
    "#     for i in range(5):\n",
    "#         print( label_batch[i].numpy(), text_batch.numpy()[i].decode('ascii') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the Dataset for Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed a 1000-word vocabulary into 5 dimensions\n",
    "embedding_layer = tf.keras.layers.Embedding( 1000, 8 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03287995,  0.02945367,  0.01589883,  0.02752216,  0.00812225,\n",
       "         0.04390066, -0.04882411,  0.00359597],\n",
       "       [ 0.03056015,  0.04533662,  0.04216014, -0.04893019, -0.04581586,\n",
       "         0.00010297,  0.03317013, -0.00468122],\n",
       "       [ 0.04515883, -0.01694564, -0.02838172, -0.03202998, -0.00071923,\n",
       "        -0.02593068,  0.01548853,  0.03944108]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = embedding_layer(tf.constant([1, 2, 3]))\n",
    "result.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3, 8])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = embedding_layer(tf.constant([[0, 1, 2], [3, 4, 5]]))\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom standardization function to strip HTML break tags '<br />'.\n",
    "def custom_standardization(input_data):\n",
    "  lowercase = tf.strings.lower(input_data)\n",
    "  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "  stripped_punct = tf.strings.regex_replace(stripped_html, '[%s]' % re.escape(string.punctuation), '')\n",
    "  return stripped_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary size and number of words in a sequence.\n",
    "vocab_size = 10000\n",
    "sequence_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use the text vectorization layer to normalize, split, and map strings to\n",
    "# integers. Note that the layer uses the custom standardization defined above.\n",
    "# Set maximum_sequence length as all samples are not of the same length.\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
    "text_ds = train_ds.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(text_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 100), dtype=int64, numpy=\n",
       "array([[  11,    7,    4, 2054,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0]], dtype=int64)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Determine the vector of integers associated with a sample string\n",
    "vectorize_layer( tf.constant(['This is a test'] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a test'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Convert a vector of integers to the associated text string\n",
    "abc = vectorize_layer.get_vocabulary()\n",
    "\" \".join( [ abc[i] for i in [  11,    7,    4, 2054, 0, 0 ] if i > 0 ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Negative => b\\'I can\\\\\\'t for the life of me remember why--I must have had a free ticket or something--but I saw this movie in the theater when it was released. I don\\\\\\'t remember who I went with, which theater I was in, or even which city. All I remember was how offended I was at this travesty someone dared to call a film, and how half the people in the theater walked out before the movie was over. Unfortunately I stuck it out to end, which I still consider to be one of the worst mistakes of my life thus far. My offense became pure horror when just before the closing credits the smarmy demon child sticks his head out from behind a sign and says \"Look for Problem Child 2, coming soon!\" That was hands-down THE most terrifying moment ever recorded on film.<br /><br />The plot, if I recall correctly, involved John Ritter and perhaps his wife (Lord, how I\\\\\\'ve tried without success to block this film out of my mind) adopting a \"problem child.\" Maybe they think they can reform him, or something. I really don\\\\\\'t know. If that was their intent, they fail miserably because from first frame to last this child remains the brattiest, rudest, most horrid demon-spawn ever to hit the big screen. Forget Damian, forget Rosemary\\\\\\'s Baby. This kid takes the cake. The only difference is, we are supposed to feel sorry for him because he\\\\\\'s a \"problem child.\" However, this is impossible since this child is quite likely the most unsympathetic character ever portrayed. You want to kill him through the entire film, and when (SPOILER, like anyone cares) John Ritter decides to keep the vile hell-child you will be yelling \"Send him back!\" in shocked disgust (like several of the people at the theater where I saw it did).<br /><br />This is only the second movie I have given a \"1\" to on the IMDb. The other was Superman IV, and by God I couldn\\\\\\'t tell you which was worse. John Ritter had a quote in TV Guide about the time that Problem Child 3, which he was not in, came out. He said something like \"The only way I would do another [Problem Child] sequel is if they dragged my dead body back to perform.\" Amen to that!<br /><br />I would rather watch a 24-hour marathon of Police Academy sequels than see even twenty minutes of Problem Child again. 1/10, only because I can\\\\\\'t give it a negative score, which is what it really deserves. Someone burn the original negatives of this film, please!\\'']\n"
     ]
    }
   ],
   "source": [
    "abc = [ x for x in train_ds ][18]\n",
    "# print( [ f\"{'Positive' if abc[1][i] else 'Negative'} => {(abc[0][i])}\" for i in range( len(abc[0] )) ] )\n",
    "print( [ f\"{'Positive' if abc[1][i] else 'Negative'} => {(abc[0][i])}\" for i in range( 1 ) ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 16\n",
    "model = Sequential( [\n",
    "    vectorize_layer,\n",
    "    Embedding( vocab_size, embedding_dim, name='embedding'),\n",
    "    GlobalAveragePooling1D(),\n",
    "#     Dense(16, activation='relu'),\n",
    "    Dense(1)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "20/20 [==============================] - 9s 419ms/step - loss: 0.6916 - accuracy: 0.5028 - val_loss: 0.6898 - val_accuracy: 0.4886\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 4s 180ms/step - loss: 0.6879 - accuracy: 0.5028 - val_loss: 0.6859 - val_accuracy: 0.4886\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 4s 178ms/step - loss: 0.6836 - accuracy: 0.5028 - val_loss: 0.6814 - val_accuracy: 0.4886\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 4s 184ms/step - loss: 0.6785 - accuracy: 0.5028 - val_loss: 0.6761 - val_accuracy: 0.4886\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 4s 183ms/step - loss: 0.6726 - accuracy: 0.5028 - val_loss: 0.6702 - val_accuracy: 0.4886\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 4s 177ms/step - loss: 0.6661 - accuracy: 0.5028 - val_loss: 0.6636 - val_accuracy: 0.4886\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 3s 176ms/step - loss: 0.6588 - accuracy: 0.5031 - val_loss: 0.6566 - val_accuracy: 0.4886\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 3s 173ms/step - loss: 0.6510 - accuracy: 0.5035 - val_loss: 0.6490 - val_accuracy: 0.4900\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 3s 176ms/step - loss: 0.6427 - accuracy: 0.5067 - val_loss: 0.6412 - val_accuracy: 0.4956\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 3s 175ms/step - loss: 0.6340 - accuracy: 0.5159 - val_loss: 0.6330 - val_accuracy: 0.5076\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 3s 173ms/step - loss: 0.6249 - accuracy: 0.5303 - val_loss: 0.6246 - val_accuracy: 0.5224\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 3s 171ms/step - loss: 0.6155 - accuracy: 0.5502 - val_loss: 0.6161 - val_accuracy: 0.5464\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 3s 172ms/step - loss: 0.6060 - accuracy: 0.5725 - val_loss: 0.6074 - val_accuracy: 0.5678\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 3s 172ms/step - loss: 0.5963 - accuracy: 0.5939 - val_loss: 0.5988 - val_accuracy: 0.5848\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 3s 169ms/step - loss: 0.5865 - accuracy: 0.6139 - val_loss: 0.5901 - val_accuracy: 0.6038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24ddb211880>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15,\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text_vectorization (TextVect (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 100, 16)           160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,017\n",
      "Trainable params: 160,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 23932), started 1:13:49 ago. (Use '!kill 23932' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7c016ffe42f68ff\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7c016ffe42f68ff\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "# %reload_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24ddbc372e0>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAqlElEQVR4nO3deXwV1fnH8c9DFgg7kgCyo6KQoEiJIBX8UZeKRXGpC1TFuiFuqK21at2lbqWugEoVF7SoVVygolJFRUEUEASMrAoiIgGRHUKS5/fHXEMIWW4gyeRevu/X675yz8yZmeeG5MnhzJlzzN0REZH4VSPsAEREpHIp0YuIxDklehGROKdELyIS55ToRUTinBK9iEiciyrRm1kfM1tgZovN7IYS6vQ2s9lmNt/MPoxsa2Vmk80sK7L96ooMXkREymZljaM3swRgIXA8sAL4HBjg7l8VqtMQmAr0cfflZtbE3Veb2f7A/u4+y8zqATOBUwsfKyIilSuaFn03YLG7L3X3HOBF4JQidf4AjHP35QDuvjry9Qd3nxV5vxHIAlpUVPAiIlK2xCjqtAC+K1ReAXQvUudgIMnMPgDqAQ+7+3OFK5hZW6ALML2sC6ampnrbtm2jCE1ERABmzpy5xt3TitsXTaK3YrYV7e9JBLoCxwIpwDQz+9TdFwKYWV3gVeAad99Q7EXMBgGDAFq3bs2MGTOiCE1ERADMbFlJ+6LpulkBtCpUbgmsLKbO2+6+2d3XAB8BnSMXTyJI8i+4+7iSLuLuo9w9090z09KK/aMkIiJ7IJpE/znQ3szamVky0B94s0idN4BeZpZoZrUJunayzMyAp4Asd3+gIgMXEZHolNl14+65ZnYl8A6QAIx29/lmNjiy/3F3zzKzt4EvgXzgSXefZ2Y9gfOAuWY2O3LKm9z9rcr4MCIisrsyh1eGITMz09VHLyISPTOb6e6Zxe3Tk7EiInFOiV5EJM4p0YuIxDklehGRauCDD+CRRyA/v+LPrUQvIhKy9eth4EAYPhy2bav480fzZKyIiFSiIUNg5Ur45BOoXbviz68WvYhIiMaNg+eeg5tugu5FZxGrIEr0IiIhWbUKBg2CX/0Kbrml8q6jRC8iEgJ3uOQS2LQJxoyBpKTKu5b66EVEQvDUUzBhAjz4IKSnV+611KIXEaliS5fCtdfCMccEN2IrmxK9iEgVyssLhlLWqAFPPx18rWzquhERqUL//GcwjPK556B166q5plr0IiJV5Msvg9E1p58O555bdddVohcRqQLbtwfJvVEjeOIJsOIWaa0k6roREakCt94Kc+cGI21SU6v22mrRi4hUsilT4B//CMbN9+1b9ddXohcRqUQbN8L550O7dvBASCtnq+tGRKQS/elPsGwZfPQR1K0bTgxq0YuIVJLx4+HJJ+H66+Goo8KLQ4leRKQSZGfDxRfDYYfB7beXXnfVplVMWDih0mJRohcRqWDucOml8PPP8PzzULNm6fXvmXIPZ/3nLH7c9GOlxKM+ehGRCvbcc/Daa3D//XDooWXXv//4+zm709k0rdu0UuKJqkVvZn3MbIGZLTazG0qo09vMZpvZfDP7sDzHiojEi2XLgonKevUKbsSWZum6pWzL3UbNxJr8utWvKy2mMhO9mSUAI4ATgXRggJmlF6nTEBgJ9HP3DODMaI8VEYkX+flwwQXB12efhYSEkuvm5OVwwvMncOZ/zqz0uKLpuukGLHb3pQBm9iJwCvBVoTp/AMa5+3IAd19djmNFROLCww/D5MnBXPPt2pVeNzkhmYdOeIiGtRpWelzRdN20AL4rVF4R2VbYwUAjM/vAzGaa2cByHAuAmQ0ysxlmNiM7Ozu66EVEqon58+HGG6Ffv6BVX5ptudsA6HtwX45qXfnjLqNJ9MVNveNFyolAV6AvcAJwi5kdHOWxwUb3Ue6e6e6ZaWlpUYQlIlI95OTAeedB/fowalTpE5Yt+WkJ7R5ux38X/rfK4oum62YF0KpQuSWwspg6a9x9M7DZzD4COkd5rIhITLvrLvjii2CkTdMyBs6kJKXw61a/5tCmUQzHqSDRtOg/B9qbWTszSwb6A28WqfMG0MvMEs2sNtAdyIryWBGRmPXpp3D33fDHP8Kpp5Zdv3m95rx61qu0blBFq44QRaJ391zgSuAdguT9srvPN7PBZjY4UicLeBv4EvgMeNLd55V0bOV8FBGRqrV5c9Bl06pVcCO2NJOWTOKcceewcfvGqgmukKgemHL3t4C3imx7vEj5H8A/ojlWRCQe/OUvsGRJMNKmfv3S6y5Yu4B5q+eRUKOUMZeVxNyLvTcaqszMTJ8xY0bYYYiIlOjtt+HEE+HPf4Zhw6I7Jicvh+SE5EqJx8xmuntmcfs0142ISDmtXQsXXggZGTB0aOl1n5vzHJ99/xlApSX5sijRi4iU0xVXwJo1MGYM1KpVcr2cvByGfjSU+z65r+qCK4YmNRMRKYeXX4aXXoK//x26dCm9bnJCMtMvno4X//hQlVGLXkQkSmvXwpVXQmZmsJhIad5e/Db5nk+jlEbsl7Jf1QRYAiV6EZEo/fnPsG5dMJdNYin9IVOWTeHEF07kmdnPVFlspVHXjYhIFN59N5iR8m9/C1aNKk3P1j15+YyXObXDqVUSW1k0vFJEpAybNgULiNSsCbNnl3wDNjc/l3Vb15FWp+rn69LwShGRvXDLLfDtt8FC36WNsrnrw7s49LFDWb15dcmVQqCuGxGRUkyfHkxvcPnl0LNn6XXPzDiTxBqJNKnTpGqCi5K6bkRESpCTA127Bot8z59f8jQH+Z5PDQu3g0RdNyIie+Dee2HePHjssZKTvLtzxstncMv7t1RtcOWgRC8iUoyvvgqmN+jfH046qeR6ufm5pNVOC32sfGnURy8iUkR+PlxyCdSrV/b0w0kJSTxx8hNUx27wX6hFLyJSxMiRMHUqPPQQNCnhvuqWHVs4//Xz+WbdNwBYaesHhkyJXkSkkOXLg0W+TzgBzj235HrzV89n/ILxLPppUdUFt4fUdSMiEuEOgwcHXx9/vPRFvo9ocQTfXvMt9WuWseJINaAWvYhIxL//DRMnBjNTtm1bfJ3l65fz8vyXAWIiyYMSvYgIANnZcPXV0L17MENlSe7/5H4uGX9JtXv6tTRK9CIiwLXXwoYNwcyUCaUs6/rgCQ/y0R8/qnZPv5ZGiV5E9nkTJ8ILL8BNNwXLAxZn/ILxbM7ZTFJCEp2bda7aAPeSEr2I7NM2boRLL4X09GC0TXGWr1/O71/+PXd9dFfVBldBokr0ZtbHzBaY2WIzu6GY/b3NbL2ZzY68bi2071ozm29m88xsrJmVMvebiEjVuukmWLEimJmyZs3i67Ru0JpJ503ilqOr7zQHpSkz0ZtZAjACOBFIBwaYWXoxVae4++GR152RY1sAQ4BMd+8EJAD9Kyx6EZG9MHUqjBgR3Hzt0WP3/Ru2b2DmypkA/F/b/6NOcp0qjrBiRNOi7wYsdvel7p4DvAicUo5rJAIpZpYI1AZWlj9MEZGKtX07XHwxtGoFd99dfJ2/TvorvZ/tzZota6o0tooWzQNTLYDvCpVXAN2LqdfDzOYQJPLr3H2+u39vZsOA5cBW4F13f3dvgxYR2Vt33w1ZWcGN2Lp1i69z1zF38dsDf0tq7dSqDa6CRdOiL+7ZsKKz98wC2rh7Z+BR4HUAM2tE0PpvBzQH6phZsQ8Vm9kgM5thZjOys7OjDF9EpPzmzYN77gmmOOjTZ/f9X2V/Rb7nk1o7ldM6nlb1AVawaBL9CqBVoXJLinS/uPsGd98Uef8WkGRmqcBxwDfunu3uO4BxwK+Lu4i7j3L3THfPTEur+vUWRWTfkJcXdNk0aAAPPrj7/mU/L6Pbv7pxxwd3VH1wlSSarpvPgfZm1g74nuBm6h8KVzCzZsCP7u5m1o3gD8hagi6bI82sNkHXzbGAlo4SkdA8+miwPOALL0BqMT0yrRu05v7j7+e0DrHfkv9FmYne3XPN7ErgHYJRM6Pdfb6ZDY7sfxw4A7jMzHIJEnp/DyZnnm5mrxB07eQCXwCjKuejiIiU7ptv4G9/g9/9DgYM2HVfbn4ua7espWndplx+xOXhBFhJtGasiOwT3IOph6dNC9Z/bd161/3XT7qeF+a+wJeDv6Rx7cbhBLkXSlszVtMUi8g+YcwYmDQJhg/fPckDnHfYeeyXsl9MJvmyqEUvInFv9Wro2BE6dIApU6BGoWEoG7ZviJnphktTWotec92ISNwbMgQ2bQqmOSic5H/Y+APpI9IZ/tnw8IKrAkr0IhLXxo+Hl16Cm28OWvWFNUppxEkHn8TRbY4OJ7gqoq4bEYlb69cH0w43agQzZ0JycrDd3dmRv4PkhORwA6xA6roRkX3SDTfADz8Ei4kkF8rpwz8bTq+ne7Fu67rwgqtCSvQiEpemTg0W+B4yBLp123Vfy/otab9fexrUahBOcFVMXTciEnd27ICuXeHnn+Grr3ZOWubumBU3fVfsU9eNiOxTHn4Y5s6FRx7ZmeQ352ym59M9ef3r10ONLQxK9CISV5Yvh9tug5NPhlMKrZyxecdmDCMlMSW84EKiJ2NFJK4MGRJ8ffRRKNxL06ROE6ZcMCVuu25Koxa9iMSNN9+EN94IWvRt2gTbJiycwB9f/yPbcrftk0kelOhFJE5s3gxXXRWMm7/22p3bv17zNfOz51MdB55UFXXdiEhcuPPOoH9+yhRIStq5/bpfX8eQ7kPi6uGo8lKLXkRi3ty58MADcNFF0LNnsO3hTx9mxspgmPa+nORBLXoRiXH5+XDZZcHSgPfdF2zblLOJYdOGsXDtQjKbFzu0fJ+iRC8iMe3pp+GTT2D0aGgcmUq+bnJd5l42lwRLCDe4akJdNyISs9asgeuvh1694Pzzg22zV83G3WlYqyH1atYLN8BqQoleRGLW9dfDhg3w2GPBPPNLflpCt3914+4pd4cdWrWirhsRiUkffRR029xwQzCkEqBdo3Y81vcxTj7k5HCDq2Y0qZmIxJycHOjSBbZsCRb6rl0b8j2fGrbvdlJoUjMRiSsPPBDMSjl8eJDkl/28jPQR6Xyy/JOwQ6uWlOhFJKZ8803wcNTpp0PfvsG2TTmbaFy7MS3rtww3uGoqqkRvZn3MbIGZLTazG4rZ39vM1pvZ7Mjr1kL7GprZK2b2tZllmVmPivwAIrLvcA+mOahRAx56aOf2jCYZfHLhJ7Rp2Ca02KqzMhO9mSUAI4ATgXRggJmlF1N1irsfHnndWWj7w8Db7t4B6AxkVUDcIrIPev11+O9/gxZ9q1aQvTmboR8NZXvu9rBDq9aiadF3Axa7+1J3zwFeBE4p4xgAzKw+cDTwFIC757j7z3sYq4jswzZuDKYg7tx551TE47LGceeHd7Jk3ZJwg6vmokn0LYDvCpVXRLYV1cPM5pjZRDOLDHbiACAbeNrMvjCzJ82sTnEXMbNBZjbDzGZkZ2eX5zOIyD7g9tvh+++DdWATIwPDL828lAVXLiA9rbhOBvlFNIm+uAmci47JnAW0cffOwKPA65HticCvgMfcvQuwGditjx/A3Ue5e6a7Z6alpUUTu4jsI2bPDpYHHDQIjjwSNm7fyLKflwHB2HkpXTSJfgXQqlC5JbCycAV33+DumyLv3wKSzCw1cuwKd58eqfoKQeIXEYlKfj4MHgz77Qf33BNsu3XyrRz2+GGs2bIm3OBiRDRPxn4OtDezdsD3QH/gD4UrmFkz4Ed3dzPrRvAHZG2k/J2ZHeLuC4Bjga8q9iOISDz7179g+nQYMwYaNQq2XXPkNaSnpZNaOzXc4GJEmYne3XPN7ErgHSABGO3u881scGT/48AZwGVmlgtsBfr7zkdurwJeMLNkYClwQSV8DhGJQ6tXB1Mc/OY3cM454O6YGW0atuGSrpeEHV7M0BQIIlJtDRwIL74IX34JHTrAbZNv49v13/JUv6dIrKGpugrTFAgiEnMmTw66a/761yDJAyTUSCDREpXky0ktehGpdrZvD8bL79gB8+ZBSsrOfb9038iu1KIXkZjyj3/AggUwYkSQ5MfOHVuw/quSfPkp0YtItbJkCQwdCmedBX36QG5+Lrd/eDt3fXRX2KHFLHV0iUi14Q5XXgnJyfDgg8G2xBqJfHbxZ2zL3RZucDFMLXoRqTZeeQXefhv+/ndo3hwWrV2Eu9OgVgOa1m0adngxS4leRKqFDRvg6qvhV7+Cyy+HNVvW0P3J7lz37nVhhxbz1HUjItXCLbfAqlXwxhuQkACNUxpz33H30atNr7BDi3lK9CISupkzg2UBL78cjjhi5xBKPf1aMdR1IyKh2rEjmJWySZOgb379tvUc+dSRvLf0vbBDixtq0YtIqIYOhVmz4NVXoUEDWPxTNrn5udSvWT/s0OKGEr2IhOazz4JW/MCBwWLfAAftdxAzLpmhB6MqkLpuRCQUW7bAeedBixbwyCOwLXcbw6YOY1vuNiX5CqZELyKhuP56WLgQnnkm6LIZv2A8f5n0F6avmF7msVI+6roRkSr37rvBPDbXXhvMNQ9wZsaZzE2bS6cmncINLg6pRS8iVWrdOrjgAujYMeifz/d8Vm1aBaAkX0mU6EWkSl1xRbBy1PPPBzNTjpkzhgMfOZB5q+eFHVrcUteNiFSZl16CsWPhrruCqQ4AerXpxdXdryY9LT3c4OKYFh4RkSrx/fdw6KFwyCEwZQokqplZobTwiIiEyh0uuihYOeq554Ik/826b7j4zYtZvXl12OHFPSV6Eal0jz0G77wDw4ZB+/bBtmkrpjEuaxw78naEG9w+QF03IlKpFi0K1n89+miYOBEKPwu1KWcTdZPrhhdcHNnrrhsz62NmC8xssZndUMz+3ma23sxmR163FtmfYGZfmNmEPfsIIhKLcnODp19r1YLRo4Mkn5efx9wf5wIoyVeRMhO9mSUAI4ATgXRggJkVd3t8irsfHnndWWTf1UDWXkcrIjHl3nth+vSg66Z582Dbc3Oeo/Pjnfns+8/CDW4fEs19727AYndfCmBmLwKnAF9FcwEzawn0Bf4O/GkP4xSRGDNzJtxxBwwYAGefvXP76R1PZ1POJo5ofkR4we1joum6aQF8V6i8IrKtqB5mNsfMJppZRqHtDwHXA/l7HKWIxJStW4MumyZNgqkOCmtQqwFXdb9KE5dVoWgSfXH/GkXv4M4C2rh7Z+BR4HUAMzsJWO3uM8u8iNkgM5thZjOys7OjCEtEqqubboKsLHj6aWjUKNi2+KfF/HbMb1n80+Jwg9sHRZPoVwCtCpVbAisLV3D3De6+KfL+LSDJzFKBo4B+ZvYt8CJwjJk9X9xF3H2Uu2e6e2ZaWlr5P4mIVAvvvw8PPRRMdfDb3+7cvuSnJSxZt0Q3YENQ5vBKM0sEFgLHAt8DnwN/cPf5heo0A350dzezbsArBC18L1SnN3Cdu59UVlAaXikSm9avD55+TUmBL76A2rV33Z+Xn0dCjYRwgotzpQ2vLPNmrLvnmtmVwDtAAjDa3eeb2eDI/seBM4DLzCwX2Ar09+o4QF9EKtWQIbByJUydujPJ5+bnMmnJJPoc1EdJPiR6YEpEKsS4cfD738OttwajbX4xZs4YBr4+kPcHvs9v2v0mvADj3F616EVEyrJqFQwaBF27ws0377pvwKEDSElKoXfb3qHEJkr0IrKX3OHii2HzZhgzBpKSdu7L93wSayRyRvoZ4QUomtRMRPbOk0/Cf/8bPAXbsePO7V+v+ZpOIzsx64dZ4QUngBK9iOyFpUuDdV+PPRauumrXfRu2b6BhrYa0rN8ynOCkgLpuRGSP5OXBwIHB3PJPPw01ijQbu7XoxtSLpoYTnOxCLXoR2SPDhsEnn8Dw4dCq0COVO/J2MGrmKHLycsILTnahRC8i5TZnDtxyC5xxBpxzzq77JiycwKUTLuW9pe+FE5zsRuPoRaRctm+HI46A1ath3jxITd29zrTvpnFkyyM1cVkV0jh6Eakwt9wCc+fChAm7J/mtO7aSkpRCj1Y9wglOiqWuGxGJ2gcfBH3zgwZB37677pu3eh6tH2rN5G8mhxKblEyJXkSiMmsWnHpqsLj3P/+5+/6aCTXp3bY3hzU9rMpjk9Kp60ZEyjR/fjDlcIMG8O67ULeYmYbbN27Pf878T9UHJ2VSi15ESrVoERx3HCQnw3vvQZs2u+7Pycvhtsm3sXbL2nAClDIp0YtIib79NnjqNTcX/vc/OOig3et8tOwjhk4ZyucrP6/y+CQ66roRkWJ9/32Q5DduhMmTIT29+HrHHXAci69aTLtG7ao2QImaWvQispsffwySfHY2vPMOHH548fVWb14NoCRfzSnRi8gufvoJjj8eli8PZqXs1q34erNXzabVg614Leu1qg1Qyk1dNyJSYP16OOEEWLgweCCqV6+S67ao14IrjrhCC4rEACV6EQGChUP69oXZs+G114KRNqVJq5PGAyc8UCWxyd5R142IsHUr9OsH06bB2LFw0kkl192Wu42L37yYRWsXVV2AsleU6EX2cTk5wSyUkyfDs88G70szZ9Uc/vPVf1i2flnVBCh7TV03Ivuw3FwYMADeegueeALOPbfsY7q37M6ya5bRsFbDSo9PKoZa9CL7qLw8OP98GDcOHnwwmKisNNtzt/P6168DKMnHmKgSvZn1MbMFZrbYzG4oZn9vM1tvZrMjr1sj21uZ2WQzyzKz+WZ2dUV/ABEpv/x8GDwY/v1vuPtuuOaaso8Z8fkITnvpNOasmlPp8UnFKrPrxswSgBHA8cAK4HMze9PdvypSdYq7F72Fkwv82d1nmVk9YKaZTSrmWBGpIu5BYn/ySbj5ZrjxxuiOG9J9COlp6XRu1rlS45OKF02Lvhuw2N2XunsO8CJwSjQnd/cf3H1W5P1GIAtosafBisjecQ8S+6OPwp/+BHfeWVZ9Z9TMUWzYvoHEGon0OahP1QQqFSqaRN8C+K5QeQXFJ+seZjbHzCaaWUbRnWbWFugCTC/uImY2yMxmmNmM7OzsKMISkfIaOhTuuy/othk2DMpa6S9rTRZXvHUFT8x4omoClEoRzaib4n4Uii40Owto4+6bzOx3wOtA+4ITmNUFXgWucfcNxV3E3UcBoyBYMzaKuESkHIYNg1tvDW7AjhhRdpIHSE9L59OLPqXL/l0qP0CpNNG06FcArQqVWwIrC1dw9w3uviny/i0gycxSAcwsiSDJv+Du4yokahEpl5Ej4S9/gbPPhqeeghpl/Oa/PP9lPvz2QwC6Nu9KDdMAvVgWTYv+c6C9mbUDvgf6A38oXMHMmgE/urubWTeCPyBrLVgC/ikgy931rLRICJ5+Gq64Ak45BcaMgYSE0uvn5udy95S7aVa3GUe3ORqLpukv1VqZid7dc83sSuAdIAEY7e7zzWxwZP/jwBnAZWaWC2wF+keSfk/gPGCumc2OnPKmSKtfRCrZiy/CRRcFywC+9BIkJZV9TGKNRP438H8k1UhSko8T5l79usMzMzN9xowZYYchEtNefz2YzuCoo2DiRKhdu/T6s1fNZuzcsdxz3D3qqolBZjbT3TOL26d/TZE4k58f3Gw9+2zIzAymGy4ryQO8ueBNxs4by5otayo/SKlSatGLxJElS4Kumg8/DOaVf/FFaNgwumPdnZ+2/kTj2o0rNUapHGrRi8S5/Hx45BE47DD44gsYPTrorikryWdvzqbf2H4s+3kZZqYkH6eU6EVi3OLF0Ls3XH118HX+fLjggujGyS9bv4wZK2fw3Ybvyq4sMUvTFIvEqLy8YCqDm26C5GR45hkYODC6BO/umBmZzTNZMmQJKUkplR6vhEctepEYtHAh/N//wbXXwjHHBK3488+PLsnvyNvB6S+fzrOznwVQkt8HKNGLxJC8PHjgAejcOUjuzz0H48dDi3JMFZiTl8PmnM1s2bGl8gKVakVdNyIxYsGCoO992rRgfdfHH4f994/+eHcnz/Ook1yHiedMJKFGGY/IStxQi16kmsvLCyYkO/xw+PpreP754GGo8iR5gNs/uJ1+Y/uxPXe7kvw+Ri16kWosKwsuvBA+/RROPRUeewyaNduzc7Ws35KVG1eSnJBcoTFK9acWvUg1lJsL998PXbrAokUwdmywtuueJPlNOZsAuKTrJfyr3780f80+SIlepJr56qtgfpq//hX69g1uuvbvH92ImqLGLxjPgY8cyNwf51Z8oBIzlOhFqoncXLj33qAVv3RpMNvkK69A06Z7fs6MJhkc2+5Y2jVqV3GBSsxRohepBubNgx49gvVc+/ULWvFnnbVnrXiABWsW4O4c0OgA/v37f1M3uW7FBiwxRYleJCS5ufD553DzzdC1KyxbBi+/DP/5DzRpsufnnfXDLA597FD+NetfFResxDSNuhGpIps2wfTp8PHHMGVKMJJm8+Zg31lnwfDhkJa299c5vNnh3NH7Ds5MP3PvTyZxQYlepJKsXg2ffBIk9Y8/hlmzgjHxZsGTrRdcAL16BTdey/Nka3F25O3gjg/v4JojryG1dio39rqxYj6ExAUlepEK4B7cQP0lqU+ZEsxHA1CzJnTvDjfcAD17Bn3xDRpU7PWz1mTxz2n/5IBGB3Bhlwsr9uQS85ToRfZAXh7MmbMzqX/8MaxaFexr1ChI6BddFHzt2jVI9pVhe+52aibW5LCmh7HgygW0btC6ci4kMU2JXvZ57rB9O2zdCtu2Ba/i3m/dGkxBMGVKMN/Mxo3B8W3awLHHBkm9Vy/o2BFqVMEwhwVrFnDC8ycwsu9Iftf+d0ryUqK4SvTjxwctLYkd7sG/WW7uzlfhcmn7Sivv2FF6wi68bfv26OM1g06d4Nxzg6Tesye0alV535/StKjfgs7NOtOyfstwApCYEVdrxtapA1s08+o+ISEBEhN3voqWExMhJQVq1Qpev7wvblt59rdsGXTNhOm/C//Lbw/8LUkJSeEGItVKaWvGxlWLftq0YO1MiS0lJeySknmNGnv+IFGs++KHLzhp7Ek8dMJDXH3k1WGHIzEiqkRvZn2Ah4EE4El3v7fI/t7AG8A3kU3j3P3OaI6tSIcdVllnFqkeuuzfhTf6v8GJB50YdigSQ8q8ZWRmCcAI4EQgHRhgZunFVJ3i7odHXneW81gRKcG6res47aXTyMrOAqDfIf3UbSPlEs3YgG7AYndf6u45wIvAKVGef2+OFRHg520/M3PlTL5e83XYoUiMiibRtwC+K1ReEdlWVA8zm2NmE80so5zHYmaDzGyGmc3Izs6OIiyR+Pbd+uBXp12jdiy8aiGndTwt5IgkVkWT6Iu77VV0qM4soI27dwYeBV4vx7HBRvdR7p7p7plpFTHhh0gM+/LHL+kwogNPzXoKgFqJtUKOSGJZNIl+BVB4pHBLYGXhCu6+wd03Rd6/BSSZWWo0x4rI7jLSMrim+zWcdPBJYYcicSCaRP850N7M2plZMtAfeLNwBTNrZpH1ycysW+S8a6M5VkQC+Z7P/Z/cz7qt60iokcDfj/07TevuxaojIhFlDq9091wzuxJ4h2CI5Gh3n29mgyP7HwfOAC4zs1xgK9Dfgyexij22kj6LSEybt3oeN79/M3WT63L5EZeHHY7Ekbh6MlYkFuXm55JYI2hzZWVn0SG1gxbwlnIr7clYrTAlEqKs7Cw6DO/Ae0vfA6BjWkclealwSvQiVcjdmfrdVKYsmwJA24Ztad+4vdZ0lUoVV3PdiFRX+Z5PDQvaVRe+cSGtGrRi0nmTSElKYeI5E0OOTuKdWvQileyR6Y/QaWQn8vLzMDNeOesVXjv7tbDDkn2IEr1IBduyYwujvxjNhu0bAGjXsB09WvZgY06wUkmnJp3UVSNVSl03IhUkLz+PhBoJzF89n4vevIjEGokM7DyQkw85mZMPOTns8GQfpha9yF7Kzc/lmGeP4eb3bwYgs3kmn138Gecddl7IkYkElOhF9sCSn5Ywdu5YABJrJNKpSSfaNWoHgJlxRIsjNExSqg113YhEqfCDTQ9Pf5invniKkw85mbrJdXnkxEdCjk6kZGrRiwDbcrcxe9Vs1m1dB8CitYsYPGFwwRzw7yx+h5pDazJv9TwAbuh5A4uuWqSbqhITlOglbrk7ufm5AGzK2cQzs58pWKXp25+/5cgnj2TiomAM+9drvqbLE12Y/O1kADbv2My4rHGs2LACgENSD+Fvvf5GvgeLEjev15zm9ZpX9UcS2SNxlejn/jiXjJEZfPjthwDM+mEWGSMzmPrdVACmr5hOxsgMZqwM5tH5ePnHZIzMYM6qOQC8/837ZIzMKEgG7yx+h4yRGSz+aTEAExZOIGNkBst+XgbAuKxxZIzM4IeNPwDw0ryXyBiZwZotawAYM2cMGSMzWL9tPQCjvxhNxsgMtuzYAsATM54gY2QGO/J2APDo9EfpNLJTwed5YNoDdHmiS0H5vo/vo/uT3QvKQz8aSs/RPQvKt02+jd88+5uC8o3/u5ETnj+hoHzdu9dx0r93Tns7ZOIQTn/p9ILyZRMu4+xXzi4oX/zmxZw77tyC8sDXBnLBGxcUlAe8OoBB4wcVlH//8u+58q0rC8r9xvbj2revLSif+MKJXD/p+oLysc8dW3ADE+Dop4/mjg/uKCj3eKoH90y5p6CcOSqTYVOHFZQ7P96Zhz99GAgeSMoYmcFjnz8GBKsy1b67NsM/Gw4ELfYL3riAd5e8C0C95HrUr1m/oCvmoP0O4tWzXqVHyx4AHN7scFb/ZTXHHXAcEDzBeudv7uSwplqYWGJPXPXRpySlkJ6WXvDf6dpJtUlPS6dOUp1dyrWTagNQJ6kO6WnppCSlAMEvf3paesEiD/Vr1ic9LZ2aCTUBaFCzAelp6SQnJAPQsFZD0tPSC5JFo5RGpKelk2AJAOyXsl9QrhGUG6c0Jj0tveAJydTaqaSnpRfctGtSpwnpaTuX1G1apykdUzvuLNdtSofUDgXlZnWbcUjjQwrK+9fbn4P3O7ig3Lxe84Kx3AAt6rUo+KMC0Kp+q4LPAtC6QWsa1GpQUG7ToA3b87YXlNs2bFvw2SAYH/7L9xbggIYHkFo7taB8YKMDaVm/ZUH5oEYH0aLezgXGDt7v4F1axYc0PoT96+2/S7lZ3WYF5Q6pHWhaZ+e0vR1TO9KkTpOCcnpaesH1G9RswJBuQ+i6f1cg+N4vGbKk4HqNazfm3fPeLTi2bnJdTu+484+eSDzR7JUiInFAs1eKiOzDlOhFROKcEr2ISJxTohcRiXNK9CIicU6JXkQkzinRi4jEOSV6EZE4Vy0fmDKzbGDZHh6eCqypwHAqUyzFCrEVbyzFCrEVbyzFCrEV797E2sbd04rbUS0T/d4wsxklPR1W3cRSrBBb8cZSrBBb8cZSrBBb8VZWrOq6ERGJc0r0IiJxLh4T/aiwAyiHWIoVYiveWIoVYiveWIoVYiveSok17vroRURkV/HYohcRkULiJtGbWR8zW2Bmi83shrDjKY2ZtTKzyWaWZWbzzezqsGMqi5klmNkXZjYh7FjKYmYNzewVM/s68j3uEXZMJTGzayM/A/PMbKyZ1Qo7psLMbLSZrTazeYW27Wdmk8xsUeRrozBj/EUJsf4j8nPwpZm9ZmYNQwxxF8XFW2jfdWbmZpZa3LHlFReJ3swSgBHAiUA6MMDM0ks/KlS5wJ/dvSNwJHBFNY8X4GogK+wgovQw8La7dwA6U03jNrMWwBAg0907AQlA/3Cj2s0zQJ8i224A3nP39sB7kXJ18Ay7xzoJ6OTuhwELgRurOqhSPMPu8WJmrYDjgeUVdaG4SPRAN2Cxuy919xzgReCUkGMqkbv/4O6zIu83EiSiFqUfFR4zawn0BZ4MO5aymFl94GjgKQB3z3H3n0MNqnSJQIqZJQK1gZUhx7MLd/8I+KnI5lOAZyPvnwVOrcqYSlJcrO7+rrvnRoqfAi13OzAkJXxvAR4Ergcq7AZqvCT6FsB3hcorqMaJszAzawt0AaaHHEppHiL4wcsPOY5oHABkA09HupqeNLM6ZR0UBnf/HhhG0HL7AVjv7u+WflS10NTdf4Cg0QI0KaN+dXEhMDHsIEpjZv2A7919TkWeN14SvRWzrdoPJzKzusCrwDXuvqGs+mEws5OA1e4+M+xYopQI/Ap4zN27AJupPl0Lu4j0bZ8CtAOaA3XM7Nxwo4pPZvY3gi7TF8KOpSRmVhv4G3BrRZ87XhL9CqBVoXJLqtl/gYsysySCJP+Cu48LO55SHAX0M7NvCbrEjjGz58MNqVQrgBXu/sv/kF4hSPzV0XHAN+6e7e47gHHAr0OOKRo/mtn+AJGvq0OOp1Rmdj5wEnCOV+/x5AcS/NGfE/l9awnMMrNme3vieEn0nwPtzaydmSUT3NB6M+SYSmRmRtCHnOXuD4QdT2nc/UZ3b+nubQm+r++7e7Vtdbr7KuA7MzsksulY4KsQQyrNcuBIM6sd+Zk4lmp647iIN4HzI+/PB94IMZZSmVkf4K9AP3ffEnY8pXH3ue7exN3bRn7fVgC/ivxM75W4SPSRmy1XAu8Q/KK87O7zw42qVEcB5xG0jmdHXr8LO6g4chXwgpl9CRwO3B1uOMWL/K/jFWAWMJfg97FaPcVpZmOBacAhZrbCzC4C7gWON7NFBKND7g0zxl+UEOtwoB4wKfJ79nioQRZSQryVc63q/T8ZERHZW3HRohcRkZIp0YuIxDklehGROKdELyIS55ToRUTinBK9iEicU6IXEYlzSvQiInHu/wHq5DW1SYFlWQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot( 'accuracy', 'b-', data=model.history.history )\n",
    "plt.plot( 'val_accuracy', 'g:', data=model.history.history )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the Trained Word Embeddings and Save them to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_layer('embedding').get_weights()[0]\n",
    "vocab = vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.open('./data/vectors.tsv', 'w', encoding='utf-8') as out_v:\n",
    "    with io.open('./data/metadata.tsv', 'w', encoding='utf-8') as out_m:\n",
    "        for index, word in enumerate(vocab):\n",
    "            if index == 0:\n",
    "                continue    # skip 0, it's padding\n",
    "                \n",
    "            vec = weights[index]\n",
    "            out_v.write( '\\t'.join( [ str(x) for x in vec ]) + '\\n' )\n",
    "            out_m.write( word + '\\n' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Embeddings\n",
    "* Tensorflow Embedding Projector: http://projector.tensorflow.org/\n",
    "* Click on \"Load data\".\n",
    "* Upload the two files you created above: vecs.tsv and meta.tsv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a32e172698e50824da0c33bd5d955f0bc05a5b3df854aad51c6c7dfa51d03fde"
  },
  "kernelspec": {
   "display_name": "Python [conda env:py38]",
   "language": "python",
   "name": "conda-env-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
